# iHearU
End-to-End Communication Application for Hearing Impaired &amp; Normal Individuals


![iHearU Logo](https://github.com/Mozasbugs/iHearU/assets/103077062/627c7bba-7cb7-4a2d-b75f-613e5a8ddb15)


## Table of Contents
- [Introduction](#introduction)
- [Features](#features)
- [Technologies Used](#technologies-used)
- [Getting Started](#getting-started)
- [Usage](#usage)
- [Contributing](#contributing)
- [Acknowledgments](#acknowledgments)
- [License](#license)

## Introduction
iHearU is an innovative application that aims to break down communication barriers between hearing impaired individuals and those with normal hearing abilities. Inspired by the need for inclusive interactions, iHearU presents a comprehensive solution that integrates modern technology with a deep commitment to creating a more connected and empathetic world.

## Features
- **Sign to Text:** The "Sign to Text" component of iHearU harnesses the power of Unity, a dynamic and versatile development platform. Users can input text, and the application's animated avatar intuitively performs corresponding sign language gestures. This feature not only enables the hearing impaired to express themselves more effectively but also fosters understanding and inclusion among a broader audience.

- **Text to Sign Language:** The "Text to Sign Language" aspect of iHearU employs a state-of-the-art deep learning model known as the "Gesture Recognizer." This model has been meticulously trained on an expansive dataset, enabling it to accurately translate American Sign Language (ASL) gestures captured by a camera into textual information. This transformative technology empowers hearing impaired individuals to communicate fluently and naturally in sign language, while simultaneously allowing those who do not understand sign language to comprehend their messages.

## Technologies Used
iHearU is a fusion of cutting-edge technologies and creative methodologies:
- **Unity:** The Unity development platform forms the cornerstone of iHearU's user interface, providing a seamless and engaging experience for users to interact with the application's features.
- **Maya:** The Maya 3D modeling and animation software is instrumental in crafting the detailed avatars and lifelike sign language animations that enhance the user experience.
- **TensorFlow:** The powerful TensorFlow deep learning framework underpins the "Gesture Recognizer" model, enabling precise and efficient translation of sign language gestures.
- **MediaPipe:** MediaPipe's hand gesture recognition capabilities facilitate real-time capture and interpretation of ASL gestures, ensuring accurate communication translation.

## Getting Started
1. Clone the repository: 'https://github.com/Mozasbugs/iHearU.git'
2. Set up Unity environment: [Unity Installation Guide](https://unity.com/)
3. Install required Python packages
4. Download pre-trained model weights

## Usage
1. Launch Unity application.
   
![1](https://github.com/Mozasbugs/iHearU/assets/103077062/7b0b8303-5363-493a-8fb5-8917ca9234f9)     ![2](https://github.com/Mozasbugs/iHearU/assets/103077062/e5b0ade2-6185-4ad7-a22d-6e67cdc50708)


2. Use the "Sign to Text" feature to see sign language gestures corresponding to text input.


![3](https://github.com/Mozasbugs/iHearU/assets/103077062/ffec36b4-d6f4-4761-8d1e-d7e35acbcb2d)


3. Use the "Text to Sign Language" feature to translate ASL gestures into text.

![photo_2023-07-14_20-11-44](https://github.com/Mozasbugs/iHearU/assets/103077062/8268a84b-690a-465b-9eef-f75eecb92157)

## Contributing
We welcome and appreciate contributions to iHearU! To learn more, please follow our [Contribution Guidelines](CONTRIBUTING.md).

## Acknowledgments
We express sincere gratitude to the following individuals who played a pivotal role in shaping iHearU:
- Mohamed Ezz El-Dein
- Ahmed Adel
- Mostafa Elnagar
- Moaz Atef

## License
This project is licensed under the [MIT License](LICENSE).
